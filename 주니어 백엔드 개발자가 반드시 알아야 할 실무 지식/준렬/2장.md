## 처리량과 응답시간

클라이언트→ 서버 데이터 요청 과정

1. 서버에 연결 : TCP를 이용해서 서버에 연결한다.
2. 데이터 전송: 정해진 규칙(프로토콜) 에 따라 데이터를 서버에 전송한다.

### 응답시간

- 응답 시간의 측정 방법

  - TTFB : 응답 데이터 중 첫번째 바이트가 도착할 때까지 걸린 시간
  - TTLB : 응답 데이터 중 마지막 바이트가 도착할 때까지 걸린 시간

- 응답시간의 구성 요소
  - 로직 수행 시간 (if, for 등)
  - DB 연동(SQL 실행)
  - 외부 API 연동
  - 응답 데이터 생성(전송)
  → 보통 외부 API 를 연동하거나 DB를 연동하는 시간이 응답시간에 많은 부분을 차지하기 때문에 응답시간을 줄일 때 DB 연동과 API 연동 시간에 집중한다.

### 처리량(Throughput)

단위 시간당 시스템이 처리하는 작업량

- 처리량 표현법
  - TPS
    - 초당 트랜잭션의 수 해당 초 동안 완료된 트랜잭셔느이 개수를 의미한다.
    - 최대 TPS 는 시스템이 처리할 수 있는 최대 요청 수를 의미한다.
      - 요청이 최대 TPS 를 초과하면 최대 TPS 수를 처리한 이후 나머지 트랜잭션이 실행된다.
  - RPS
    - 초다 요청의 수
- 처리량을 늘리는 법.
  1. 트래픽이 많은 시간대에 TPS 와 응답시간을 측정하기
  2. 목표 TPS 와 응답시간을 설정하기
  → 이를 가장 쉽게 알 수 있는 방법은 모니터링 시스템을 활용하는것임
- 트래픽 모니터링 시스템
  -

## 서버 성능 개선 기초

서비스 초기에는 성능 문제가 잘 발생하지 않으나 점차 사용자가 늘면서 성능문제가 발생하기 시작함.

그때 보이는 지표는 다음과 같음

- 순간적인 모든 사용자 요청에 대한 응답시간이 심각하게 느려짐
- 서버를 재시작하면 잠시 괜찮았다가 다시 응답시간이 느려짐
- 트래픽이 줄어들 때까지 심각한 상황이 계속됨

이러한 지표가 보이는 이유는 시스템이 수용할 수 있는 최대 TPs 보다 더 높은 트래픽이 유입되기 때문

→ 보통 이러한 성능 문제는 주로 DB 연동이나 API 연동 과정에서 발생한다.

- 수직확장과 수평확장
  수직확장(scale-up) : CPU, 메모리, 디스크 등의 자원을 증가시키는 것
  수평 확장(scale-out) : 서버를 추가로 투입해 TPS 를 높이는 방법, 로드밸런서가 필요하다.
  > 로드밸런서
  >
  > 사용자의 트래픽을 각 서버에 골고루 분배해서 한 서버에 사용자 트래픽이 몰리지 않도록 하는 것
  >
  > - 로드밸런서의 트래픽 분산 방식
  > - 로드밸런싱 알고리즘 종류
  >   - 정적인 방식
  >     - 해쉬 알고리즘
  >       - 특정 기준을 잡아 특정 서버에 매핑하고 고정적으로 트래픽을 분산해주는 방식
  >       - 일반적으로 사용되는 기준은 출발비의 IP가 됨.
  >     - 라운드 로빈 (RR) : 트래픽이 순차적으로 들어올때 서버에 순차적으로 하나씩 분산
  >       - 들어오는 트래픽을 서버 순서대로 배치하는 방식
  >       - 연결된 세션이 비교적 오래 사용되지 않은 경우에 채택하는 것이 좋음.
  >   - 동적인 방식
  >     - Leat Connection 알고리즘
  >       - 현재 매핑되어있는 커넥션이 가장 적은 서버로 세션을 연결해주는 방식
  >       - Keep Alive로 오랫동안 연결이 지속될경우 문제 발생 가능성 있음.
  >     - Weighted Round Robin
  >       - 서버의 가중치를 따라 요청을 더 분배하기도 하는 알고리즘

→ 무턱대고 서버 추가만 한다고 해결되진 않음

DB 에서 문재가 일어나는지, 외부 API 가 문제인지 등의 문제 발생 지점을 파악하는것이 우선

### DB 커넥션 풀

DB 를 사용하는 3단계

1. DB 에 연결한다
2. 쿼리를 실행한다
3. 사용이 끝나면 연결을 종료한다.

이때 네트워크 연결을 생성하고 종료하는데 걸리는 시간의 80% 이상이 DB 연결 및 종료에 쓰이게 되는것이 일반적.

이를 방지하기 위해 DB 커넥션 풀을 사용한다. 스프링 부트는 HikariCp를 사용

- 커넥션 풀 연결 과정
  ## **2️⃣ Connection Pool 추가된 상세 과정**
  ### **1. MySQL 서버 소켓 생성 & 연결 요청**
  - 기존과 동일하게 MySQL 서버는 3306 포트에서 연결을 대기.
  - 클라이언트가 연결 요청을 하면 **Connection Pool이 먼저 기존 연결을 확인**.
  - 사용 가능한 연결이 있으면 즉시 할당하고, 없으면 새로운 연결을 생성 후 추가.
  ***
  ### **2. MySQL 서버의 프로세스/스레드 생성**
  - MySQL은 기본적으로 Thread-Per-Connection 방식으로 작동하여 클라이언트 요청이 오면 새로운 스레드 또는 프로세스를 생성하지만, **Connection Pool을 사용하면 기존 연결을 재사용하여 불필요한 스레드/프로세스 생성을 방지**.
  ### **변경점**
  - 기존 방식: 새로운 요청이 오면 새로운 스레드/프로세스 생성.
  - 커넥션 풀 도입 후: 기존 연결을 재사용하여 서버 부하 감소.
  ***
  ### **3. SQL 데이터 송수신**
  - SQL 쿼리 송수신 과정은 동일하지만, **Connection Pool을 사용할 경우 클라이언트가 작업을 끝낸 후 연결을 즉시 닫지 않고 다시 풀에 반환**.
  - 기존 방식에서는 클라이언트가 연결을 종료하면 MySQL 서버가 이를 해제하지만, Connection Pool이 있으면 클라이언트가 `close()`를 호출해도 물리적인 연결이 닫히지 않고 풀에 반환됨.
- **1️⃣ 기존 SQL 연결 방식의 단점**
  과거에는 **클라이언트가 DB 서버에 접속할 때마다 새로운 연결을 생성**하는 방식(`Thread-Per-Connection` 또는 `Fork-Per-Connection`)을 사용했음.
  하지만 이 방식은 **성능 저하와 자원 낭비 문제**를 발생시켰고, 이를 해결하기 위해 **Connection Pool** 개념이 등장하게 됨.
  ### **✅ 기존 방식의 문제점**
  1. **연결 생성 오버헤드 (Connection Overhead)**
     - 클라이언트가 DB에 연결할 때마다 **TCP/IP 연결을 맺고(TCP 3-Way Handshake)**, 인증 과정을 거쳐야 함.
     - 이 과정에서 **CPU, 메모리, 네트워크 자원을 불필요하게 소모**함.
  2. **동시 연결 한계 (Connection Limit)**
     - DB 서버는 **동시에 처리할 수 있는 연결 수에 한계**가 있음.
     - 예를 들어, MySQL의 `max_connections` 기본값은 **151개**인데, 이 이상 연결하면 **DB 접속 거부(Connection Refused)**가 발생.
  3. **메모리 사용 증가 (Memory Consumption)**
     - 많은 클라이언트가 동시에 접속하면, **DB 서버가 과부하 상태**가 됨.
     - PostgreSQL처럼 **Fork-Per-Connection** 방식을 쓰는 경우, **클라이언트가 많아질수록 메모리 사용량이 급증**함.
  4. **연결 종료 시 오버헤드 (Disconnect Overhead)**
     - 클라이언트가 요청을 마치고 연결을 끊으면, **TCP 4-Way Handshake**를 수행하고 해당 프로세스 또는 스레드를 정리해야 함.

<aside>
<img src="/icons/map-pin_yellow.svg" alt="/icons/map-pin_yellow.svg" width="40px" />

커넥션풀의 단점은?

</aside>

### 1. 커넥션 풀 튜닝 🏊‍♂️

데이터베이스 커넥션을 맺는 과정은 비용이 많이 드는 작업입니다. **커넥션 풀**은 미리 일정 개수의 커넥션을 만들어두고 재사용함으로써 이 비용을 줄여주는 핵심 기술입니다.

### 동적 크기 조절 (Min/Max 설정)

서비스 트래픽은 항상 변동합니다. 예를 들어, 은행 서비스는 낮에, 게임 서비스는 저녁에 트래픽이 집중됩니다. 이런 패턴에 효율적으로 대응하기 위해 커넥션 풀의 크기를 동적으로 조절합니다.

- **`minimum-idle` (Min)**: 트래픽이 적을 때도 유지할 최소 커넥션 개수입니다. 유휴 커넥션을 너무 많이 유지하면 DB 서버에 불필요한 부하를 줍니다.
- **`maximum-pool-size` (Max)**: 트래픽 급증 시 최대로 생성할 수 있는 커넥션 개수입니다. 이 값을 초과하면 클라이언트는 커넥션을 할당받기 위해 대기해야 합니다.

### 주요 시간 설정

- **커넥션 대기 시간 (`connection-timeout`)**: 풀에 가용한 커넥션이 없을 때, 클라이언트가 커넥션을 얻기 위해 대기할 수 있는 최대 시간입니다. 이 시간을 초과하면 오류가 발생합니다.
- **최대 유휴 시간 (`idle-timeout`)**: 커넥션이 풀에서 사용되지 않고 대기할 수 있는 최대 시간입니다. 이 시간이 지나면 커넥션은 풀에서 제거되어 불필요한 자원 낭비를 방지합니다.
- **최대 유지 시간 (`max-lifetime`)**: 커넥션의 최대 수명 시간입니다. 이 시간이 지나면 사용 중이더라도 반납 시 풀에서 제거됩니다. MySQL의 `wait_timeout`(기본 8시간) 때문에 발생하는 커넥션 단절 문제를 예방하기 위해, **이 값을 DB의 `wait_timeout`보다 짧게 설정하는 것이 매우 중요합니다.**

---

### 2. 서버 캐시 전략 ⚡

스케일 아웃/업은 비용이 많이 들기 때문에, 응답 시간을 줄이기 위한 효과적인 대안으로 **캐시**를 사용합니다. 캐시는 자주 조회되는 데이터를 **키-밸류(Key-Value)** 형태로 빠른 저장소(주로 메모리)에 보관하여 느린 DB 조회를 피하게 해줍니다.

### 캐시 효율성 측정: Hit Rate

캐시의 효과성은 **캐시 히트율(Cache Hit Rate)**로 측정합니다.

- **`Cache Hit Rate (%) = (캐시에서 데이터를 찾은 횟수 / 총 조회 횟수) * 100`**
- 히트율이 높을수록 DB 부하를 효과적으로 줄이고 있다는 의미입니다.

### 캐시 교체(삭제) 정책

캐시의 메모리는 한정적이므로, 새로운 데이터 저장 공간이 부족할 때 어떤 데이터를 삭제할지 결정하는 규칙이 필요합니다.

- **LRU (Least Recently Used)**: **가장 오랫동안 사용되지 않은** 데이터를 삭제합니다. "한번 액세스한 데이터는 가까운 미래에 다시 액세스될 것이다"라는 **시간 지역성(Temporal Locality)**에 기반한 가장 일반적인 정책입니다.
- **LFU (Least Frequently Used)**: **가장 적게 사용된(액세스 빈도가 낮은)** 데이터를 삭제합니다.
- **FIFO (First-In, First-Out)**: **가장 먼저 들어온** 데이터를 순서대로 삭제하는 가장 간단한 방식입니다.

### 캐시의 종류: 로컬 캐시 vs 리모트 캐시

| 구분                                      | 로컬 캐시 (Local Cache)                                                                 | 리모트 캐시 (Remote/Distributed Cache)                                   |
| ----------------------------------------- | --------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| **개념**                                  | 애플리케이션 서버의 메모리 내부에 저장                                                  | 별도의 캐시 서버(프로세스)에 저장                                        |
| **장점**                                  | ✅**속도가 매우 빠름 (네트워크 오버헤드 없음)**✅ 구현이 간단함                         | ✅**여러 서버 간 데이터 공유 및 일관성 유지**✅ 훨씬 큰 데이터 저장 가능 |
| ✅ 애플리케이션 재시작 시에도 데이터 유지 |
| **단점**                                  | ❌**여러 서버 간 데이터 공유 불가**❌ 서버 확장(스케일 아웃) 시 데이터 불일치 문제 발생 |
| ❌ 애플리케이션 메모리 소모               | ❌**네트워크 지연 시간(Latency) 발생**❌ 별도의 캐시 서버 구축 및 관리 비용 발생        |
| **대표 사례**                             | EhCache, Caffeine, Guava Cache                                                          | **Redis**, Memcached                                                     |
| **주요 용도**                             | ·특정 서버 인스턴스에만 국한된 데이터                                                   |
| 거의 변하지 않는 전역 설정 정보           | ·사용자 세션 정보                                                                       |

여러 서버가 공유해야 하는 데이터
DB 부하를 줄이기 위한 주력 캐시 |

### 캐시 사전 적재

트래픽이 순간적으로 급등한다면 해당정보를 미리 캐시애두는 것도 고려 가능

### 캐시 무효화

유효하지 않ㅎ은 데이터를 적절한 시점에 캐시에서 삭제하는 것이 중요함

변경에 민감한 데이터는 로컬 캐시가 아니라 리모트 캐시에 보관
